{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://EM2021002716.bosonit.local:4041\n",
       "SparkContext available as 'sc' (version = 3.1.1, master = local[*], app id = local-1620827369570)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "import scala.util.Try\r\n",
       "import org.apache.spark.sql.functions._\r\n",
       "import org.apache.spark.sql.DataFrame\r\n",
       "import org.apache.spark.sql.types._\r\n",
       "import org.apache.spark.sql.SparkSession\r\n",
       "import java.io.File\r\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scala.util.Try\n",
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql.DataFrame\n",
    "import org.apache.spark.sql.types._\n",
    "import org.apache.spark.sql.SparkSession\n",
    "import java.io.File\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spark: org.apache.spark.sql.SparkSession = org.apache.spark.sql.SparkSession@6796e051\r\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val spark = SparkSession\n",
    " .builder\n",
    " .appName(\"Goodreads-Books\")\n",
    " .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Funciones**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hasColumn: (df: org.apache.spark.sql.DataFrame, path: String)org.apache.spark.sql.Column\r\n",
       "getListOfFiles: (dir: String)Array[String]\r\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Función para comprobar que existe la columna, ya que hay files con menos columnas\n",
    "def hasColumn(df: DataFrame, path: String) = {\n",
    "  if (Try(df(path)).isSuccess){\n",
    "    df(path)\n",
    "  }else{\n",
    "    lit(null)\n",
    "  }\n",
    "}\n",
    "\n",
    "// Recojo el nombre de los archivos .csv de los libros\n",
    "def getListOfFiles(dir: String): Array[String] = {\n",
    "  val d = new File(dir)\n",
    "    if (d.exists && d.isDirectory) {\n",
    "      d.listFiles.filter(_.isFile)\n",
    "        .filter(_.getName.contains(\"book\"))\n",
    "        .map(_.getPath).toArray\n",
    "    } else {\n",
    "      Array[String]()\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ruta: String = C:/Users/mario.serrano/Desktop/Goodreads-Books/datasets\r\n",
       "bookFiles: Array[String] = Array(C:\\Users\\mario.serrano\\Desktop\\Goodreads-Books\\datasets\\book1-100k.csv, C:\\Users\\mario.serrano\\Desktop\\Goodreads-Books\\datasets\\book1000k-1100k.csv, C:\\Users\\mario.serrano\\Desktop\\Goodreads-Books\\datasets\\book100k-200k.csv, C:\\Users\\mario.serrano\\Desktop\\Goodreads-Books\\datasets\\book1100k-1200k.csv, C:\\Users\\mario.serrano\\Desktop\\Goodreads-Books\\datasets\\book1200k-1300k.csv, C:\\Users\\mario.serrano\\Desktop\\Goodreads-Books\\datasets\\book1300k-1400k.csv, C:\\Users\\mario.serrano\\Desktop\\Goodreads-Books\\datasets\\book1400k-1500k.csv, C:\\Users\\mario.serrano\\Desktop\\Goodreads-Books\\datasets\\book1500k-1600k.csv, C:\\Users\\mario.serrano\\Desktop\\Goodreads-Books\\datasets\\book1600k-1700k.csv, C:\\Use...\r\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val ruta = \"C:/Users/mario.serrano/Desktop/Goodreads-Books/datasets\"\n",
    "val bookFiles = getListOfFiles(ruta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dfList: Array[org.apache.spark.sql.DataFrame] = Array([Id: string, Name: string ... 16 more fields], [Id: string, Name: string ... 18 more fields], [pagesNumber: string, Authors: string ... 16 more fields], [Id: string, Name: string ... 18 more fields], [Id: string, Name: string ... 18 more fields], [Id: string, Name: string ... 18 more fields], [Id: string, Name: string ... 18 more fields], [Id: string, Name: string ... 18 more fields], [Id: string, Name: string ... 18 more fields], [Authors: string, CountsOfReview: string ... 17 more fields], [Id: string, Name: string ... 17 more fields], [Id: string, Name: string ... 17 more fields], [Id: string, Name: string ... 17 more fields], [Publisher: string, RatingDistTotal: string ... 16 more fields], [Id: string, Name: string ... 17 more fi...\r\n"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val dfList = bookFiles.map{ file => spark.read.option(\"header\",\"true\")\n",
    "                           .option(\"quote\", \"\\\"\")\n",
    "                           .option(\"escape\", \"\\\"\")\n",
    "                           .option(\"ignoreLeadingWhiteSpace\",\"true\")\n",
    "                           .option(\"ignoreTrailingWhiteSpace\",\"true\")\n",
    "                           //.option(\"multiLine\",\"true\")  // Hay saltos de líneas en algunos registros, falla en jupyter duplicate\n",
    "                           .csv(file)}  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A continuación voy a ordenar todos los dataframes, y utilizo la función creada anteriormente <br/>\n",
    "para rellenar con null si no existe esa columna**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dfList2: Array[org.apache.spark.sql.DataFrame] = Array([Id: string, Name: string ... 18 more fields], [Id: string, Name: string ... 18 more fields], [pagesNumber: string, Authors: string ... 18 more fields], [Id: string, Name: string ... 18 more fields], [Id: string, Name: string ... 18 more fields], [Id: string, Name: string ... 18 more fields], [Id: string, Name: string ... 18 more fields], [Id: string, Name: string ... 18 more fields], [Id: string, Name: string ... 18 more fields], [Authors: string, CountsOfReview: string ... 18 more fields], [Id: string, Name: string ... 18 more fields], [Id: string, Name: string ... 18 more fields], [Id: string, Name: string ... 18 more fields], [Publisher: string, RatingDistTotal: string ... 18 more fields], [Id: string, Name: string ... 18 more f...\r\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val dfList2 = dfList.map{df =>  df.withColumn(\"Description\", hasColumn(df, \"Description\"))\n",
    "                                  .withColumn(\"Count of text reviews\",hasColumn(df,\"Count of text reviews\"))}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Una vez ordenado realizo la union de los dataframes, utilizo el distinct ya que tenemos unos cuantos datos duplicados**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unionDF: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [Id: string, Name: string ... 18 more fields]\r\n"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val unionDF = dfList2.reduce(_ unionByName _).coalesce(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Doy formato y limpio datos de las columnas RatingDist5,4,3,2,1 <br/>\n",
    "También me doy cuenta que el PublishMonth y el PublishDay están cambiados ya que los valores de PublishDay van de 1 a 12**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df: org.apache.spark.sql.DataFrame = [Id: int, Name: string ... 18 more fields]\r\n"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df = unionDF.withColumn(\"Id\",$\"Id\".cast(IntegerType))\n",
    "  .withColumn(\"Rating\",$\"Rating\".cast(DoubleType))\n",
    "  .withColumn(\"PublishYear\",$\"PublishYear\".cast(IntegerType))\n",
    "  .withColumn(\"PublishMonth\",$\"PublishMonth\".cast(IntegerType))\n",
    "  .withColumn(\"PublishDay\",$\"PublishDay\".cast(IntegerType))\n",
    "  .withColumn(\"RatingDist5\",regexp_extract($\"RatingDist5\",\"\"\"5:(\\d+)\"\"\",1).cast(IntegerType))\n",
    "  .withColumn(\"RatingDist4\",regexp_extract($\"RatingDist4\",\"\"\"4:(\\d+)\"\"\",1).cast(IntegerType))\n",
    "  .withColumn(\"RatingDist3\",regexp_extract($\"RatingDist3\",\"\"\"3:(\\d+)\"\"\",1).cast(IntegerType))\n",
    "  .withColumn(\"RatingDist2\",regexp_extract($\"RatingDist2\",\"\"\"2:(\\d+)\"\"\",1).cast(IntegerType))\n",
    "  .withColumn(\"RatingDist1\",regexp_extract($\"RatingDist1\",\"\"\"1:(\\d+)\"\"\",1).cast(IntegerType))\n",
    "  .withColumn(\"RatingDistTotal\",regexp_extract($\"RatingDistTotal\",\"\"\"total:(\\d+)\"\"\",1).cast(IntegerType))\n",
    "  .withColumn(\"CountsOfReview\",$\"CountsOfReview\".cast(IntegerType))\n",
    "  .withColumn(\"pagesNumber\",$\"pagesNumber\".cast(IntegerType))\n",
    "  .withColumn(\"Count of text reviews\",$\"Count of text reviews\".cast(IntegerType))\n",
    "  .withColumnRenamed(\"Count of text reviews\",\"CountOfTextReviews\")\n",
    "  .withColumnRenamed(\"PublishMonth\",\"PublishDay1\")\n",
    "  .withColumnRenamed(\"PublishDay\",\"PublishMonth\")\n",
    "  .withColumnRenamed(\"PublishDay1\",\"PublishDay\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Id: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- RatingDist1: integer (nullable = true)\n",
      " |-- pagesNumber: integer (nullable = true)\n",
      " |-- RatingDist4: integer (nullable = true)\n",
      " |-- RatingDistTotal: integer (nullable = true)\n",
      " |-- PublishDay: integer (nullable = true)\n",
      " |-- PublishMonth: integer (nullable = true)\n",
      " |-- Publisher: string (nullable = true)\n",
      " |-- CountsOfReview: integer (nullable = true)\n",
      " |-- PublishYear: integer (nullable = true)\n",
      " |-- Language: string (nullable = true)\n",
      " |-- Authors: string (nullable = true)\n",
      " |-- Rating: double (nullable = true)\n",
      " |-- RatingDist2: integer (nullable = true)\n",
      " |-- RatingDist5: integer (nullable = true)\n",
      " |-- ISBN: string (nullable = true)\n",
      " |-- RatingDist3: integer (nullable = true)\n",
      " |-- Description: string (nullable = true)\n",
      " |-- CountOfTextReviews: integer (nullable = true)\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "df.printSchema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cambio nulls y redondeo el Rating a 2 decimales**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cleanDF: org.apache.spark.sql.DataFrame = [Id: int, Name: string ... 18 more fields]\r\n"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val cleanDF = df.withColumn(\"Language\",when($\"Language\".isNotNull, $\"Language\").otherwise(\"n/a\"))\n",
    "  .withColumn(\"ISBN\",when($\"ISBN\".isNotNull, $\"ISBN\").otherwise(\"n/a\"))\n",
    "  .withColumn(\"Description\",when($\"Description\".isNotNull, $\"Description\").otherwise(\"Description not available\"))\n",
    "  .withColumn(\"CountOfTextReviews\",when($\"CountOfTextReviews\".isNotNull, $\"CountOfTextReviews\").otherwise(0))\n",
    "  .withColumn(\"Rating\",round($\"Rating\",2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Leo los otros archivos realacionados con los ratings dados por usuarios**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ID: string (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Rating: string (nullable = true)\n",
      "\r\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "userRDF: org.apache.spark.sql.DataFrame = [ID: string, Name: string ... 1 more field]\r\n",
       "res11: userRDF.type = [ID: string, Name: string ... 1 more field]\r\n"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val userRDF = spark.read.format(\"csv\")\n",
    "  .option(\"header\",\"true\")\n",
    "  .option(\"quote\", \"\\\"\")\n",
    "  .option(\"escape\", \"\\\"\")\n",
    "  .load(\"C:/Users/mario.serrano/Desktop/Goodreads-Books/datasets/user*.csv\")\n",
    "userRDF.printSchema\n",
    "userRDF.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Me he creado un dataframe pivoteando los valores de los ratings por usuarios y limpiado los nulls, <br/>\n",
    "se podría utilizar para ver si tiene un buen rating o no un libro**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------+--------------+---------------+--------+---------+---------------+\n",
      "|Name                                              |it was amazing|really liked it|liked it|it was ok|did not like it|\n",
      "+--------------------------------------------------+--------------+---------------+--------+---------+---------------+\n",
      "|Fun Home: A Family Tragicomic                     |33            |32             |7       |0        |0              |\n",
      "|A Blind Man Can See How Much I Love You           |3             |0              |2       |1        |0              |\n",
      "|Assembling My Father: A Daughter's Detective Story|0             |0              |1       |0        |0              |\n",
      "|The Night Watch                                   |2             |3              |6       |1        |0              |\n",
      "|Weight: The Myth of Atlas and Heracles            |2             |7              |3       |2        |0              |\n",
      "|Art and Lies                                      |2             |4              |5       |0        |0              |\n",
      "|Borrowed Light: A Novel                           |0             |0              |1       |0        |0              |\n",
      "|The Year of Magical Thinking                      |50            |68             |32      |11       |0              |\n",
      "|The Highest Tide                                  |3             |2              |7       |1        |0              |\n",
      "|The Wise Man's Fear (The Kingkiller Chronicle, #2)|28            |28             |8       |1        |1              |\n",
      "+--------------------------------------------------+--------------+---------------+--------+---------+---------------+\n",
      "only showing top 10 rows\n",
      "\r\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "pivotDF: org.apache.spark.sql.DataFrame = [Name: string, This user doesn't have any rating: bigint ... 5 more fields]\r\n",
       "booksRatingDF: org.apache.spark.sql.DataFrame = [Name: string, it was amazing: bigint ... 4 more fields]\r\n"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val pivotDF = userRDF.groupBy(\"Name\")\n",
    "  .pivot(\"Rating\")\n",
    "  .count()\n",
    "val booksRatingDF = pivotDF.select(\"Name\",\"it was amazing\",\"really liked it\",\"liked it\",\"it was ok\",\"did not like it\")\n",
    "  .withColumn(\"it was amazing\",when($\"it was amazing\".isNull, 0).otherwise($\"it was amazing\"))\n",
    "  .withColumn(\"really liked it\",when($\"really liked it\".isNull, 0).otherwise($\"really liked it\"))\n",
    "  .withColumn(\"liked it\",when($\"liked it\".isNull, 0).otherwise($\"liked it\"))\n",
    "  .withColumn(\"it was ok\",when($\"it was ok\".isNull, 0).otherwise($\"it was ok\"))\n",
    "  .withColumn(\"did not like it\",when($\"did not like it\".isNull, 0).otherwise($\"did not like it\"))\n",
    "booksRatingDF.show(10, false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lo guardo en parquet para realizar las consultas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanDF.write.format(\"parquet\").mode(\"overwrite\").save(\"C:/Users/mario.serrano/Desktop/Goodreads-Books/datasets/parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Id: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- RatingDist1: integer (nullable = true)\n",
      " |-- pagesNumber: integer (nullable = true)\n",
      " |-- RatingDist4: integer (nullable = true)\n",
      " |-- RatingDistTotal: integer (nullable = true)\n",
      " |-- PublishDay: integer (nullable = true)\n",
      " |-- PublishMonth: integer (nullable = true)\n",
      " |-- Publisher: string (nullable = true)\n",
      " |-- CountsOfReview: integer (nullable = true)\n",
      " |-- PublishYear: integer (nullable = true)\n",
      " |-- Language: string (nullable = true)\n",
      " |-- Authors: string (nullable = true)\n",
      " |-- Rating: double (nullable = true)\n",
      " |-- RatingDist2: integer (nullable = true)\n",
      " |-- RatingDist5: integer (nullable = true)\n",
      " |-- ISBN: string (nullable = true)\n",
      " |-- RatingDist3: integer (nullable = true)\n",
      " |-- Description: string (nullable = true)\n",
      " |-- CountOfTextReviews: integer (nullable = true)\n",
      "\r\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "columnarBooksDF: org.apache.spark.sql.DataFrame = [Id: int, Name: string ... 18 more fields]\r\n"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val columnarBooksDF = spark.read.format(\"parquet\").load(\"C:/Users/mario.serrano/Desktop/Goodreads-Books/datasets/parquet/*.parquet\")\n",
    "columnarBooksDF.printSchema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.- Rating promedio de todos los libros**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|Average Rating|\n",
      "+--------------+\n",
      "|       3761.15|\n",
      "+--------------+\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "columnarBooksDF.select(round(avg(\"Rating\"),2).as(\"Average Rating\")).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.- Rating promedio de los libros por autor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------+\n",
      "|             Authors|Average Rating|\n",
      "+--------------------+--------------+\n",
      "|       Ruthie Bolton|           4.1|\n",
      "|      Richard Taylor|           3.7|\n",
      "|    M. Brinton Lykes|           4.0|\n",
      "|          Carl Jones|           2.5|\n",
      "|       Jim Hightower|           3.9|\n",
      "|       Bob Flowerdew|           3.0|\n",
      "|         Maria Twist|           0.0|\n",
      "|       Triumph Books|           2.8|\n",
      "|Muhammad Ibn Jari...|           4.4|\n",
      "| M. Basil Pennington|           3.7|\n",
      "|        Jackie Marsh|           3.3|\n",
      "|        Tom Tumbusch|           4.4|\n",
      "|     Achmed Abdullah|           0.8|\n",
      "|      Nina Berberova|           3.5|\n",
      "|      Michael Tanner|           2.7|\n",
      "|        Fred Ehrlich|           3.4|\n",
      "|      Elizabeth Reis|           3.8|\n",
      "|      John C. Pickup|           2.5|\n",
      "|     Stephen McGinty|           3.2|\n",
      "|   Thomas Zimmerling|           0.0|\n",
      "+--------------------+--------------+\n",
      "only showing top 20 rows\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "columnarBooksDF.groupBy(\"Authors\")\n",
    "  .agg(round(avg(\"Rating\"),1).as(\"Average Rating\"))\n",
    "  .where(col(\"Average Rating\").isNotNull)\n",
    "  .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.- Rating promedio de los libros por Publisher**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------+\n",
      "|           Publisher|Average Rating|\n",
      "+--------------------+--------------+\n",
      "|               Seuil|          3.36|\n",
      "|               Wiley|          2.54|\n",
      "|John Benjamins Pu...|          1.53|\n",
      "|Rourke Educationa...|           2.4|\n",
      "|       Triumph Books|          3.58|\n",
      "|          BradyGames|          3.18|\n",
      "|Louisiana State U...|          3.21|\n",
      "|  Coffee House Press|          3.83|\n",
      "|     Putnam Juvenile|          3.69|\n",
      "| Stride Publications|          1.72|\n",
      "|        Tantor Media|          3.78|\n",
      "|    George Braziller|          3.55|\n",
      "|             Lorimer|          2.29|\n",
      "|American Heritage...|          2.59|\n",
      "|        Alfred Music|          1.94|\n",
      "|   B.E.S. Publishing|          3.42|\n",
      "|      Véhicule Press|          2.58|\n",
      "|Bristol Classical...|          3.48|\n",
      "|University Press ...|          1.35|\n",
      "|William B. Eerdma...|          3.49|\n",
      "+--------------------+--------------+\n",
      "only showing top 20 rows\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "columnarBooksDF.groupBy(\"Publisher\")\n",
    "  .agg(round(avg(\"Rating\"),2).as(\"Average Rating\"))\n",
    "  .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.- Número promedio de páginas de todos los libros**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|Average Pages|\n",
      "+-------------+\n",
      "|       534.44|\n",
      "+-------------+\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "columnarBooksDF.select(round(avg(\"pagesNumber\"),2).as(\"Average Pages\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.- Número promedio de páginas de todos los libros por autor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+\n",
      "|             Authors|Average Pages|\n",
      "+--------------------+-------------+\n",
      "|       Ruthie Bolton|          300|\n",
      "|      Richard Taylor|          239|\n",
      "|    M. Brinton Lykes|          392|\n",
      "|          Carl Jones|          192|\n",
      "|       Jim Hightower|          315|\n",
      "|       Bob Flowerdew|          200|\n",
      "|         Maria Twist|          128|\n",
      "|       Triumph Books|          174|\n",
      "|Muhammad Ibn Jari...|          300|\n",
      "| M. Basil Pennington|          168|\n",
      "|        Jackie Marsh|          282|\n",
      "|        Tom Tumbusch|          156|\n",
      "|     Achmed Abdullah|          288|\n",
      "|      Nina Berberova|          271|\n",
      "|      Michael Tanner|          237|\n",
      "|        Fred Ehrlich|           33|\n",
      "|      Elizabeth Reis|          293|\n",
      "|      John C. Pickup|          867|\n",
      "|     Stephen McGinty|          245|\n",
      "|   Thomas Zimmerling|           24|\n",
      "+--------------------+-------------+\n",
      "only showing top 20 rows\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "columnarBooksDF.groupBy(\"Authors\")\n",
    "  .agg(round(avg(\"pagesNumber\")).cast(IntegerType).as(\"Average Pages\"))\n",
    "  .where(col(\"Average Pages\").isNotNull)\n",
    "  .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6.- Número promedio de páginas de todos los libros por Publisher**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+\n",
      "|           Publisher|Average Pages|\n",
      "+--------------------+-------------+\n",
      "|               Seuil|          317|\n",
      "|               Wiley|          400|\n",
      "|John Benjamins Pu...|          325|\n",
      "|Rourke Educationa...|           30|\n",
      "|       Triumph Books|          214|\n",
      "|          BradyGames|          180|\n",
      "|Louisiana State U...|          249|\n",
      "|  Coffee House Press|          187|\n",
      "|     Putnam Juvenile|           69|\n",
      "| Stride Publications|          114|\n",
      "|        Tantor Media|            9|\n",
      "|    George Braziller|          200|\n",
      "|             Lorimer|          171|\n",
      "|American Heritage...|          262|\n",
      "|        Alfred Music|           80|\n",
      "|   B.E.S. Publishing|          105|\n",
      "|      Véhicule Press|          178|\n",
      "|Bristol Classical...|          203|\n",
      "|University Press ...|          243|\n",
      "|William B. Eerdma...|          291|\n",
      "+--------------------+-------------+\n",
      "only showing top 20 rows\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "columnarBooksDF.groupBy(\"Publisher\")\n",
    "  .agg(round(avg(\"pagesNumber\")).cast(IntegerType).as(\"Average Pages\"))\n",
    "  .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7.- Número promedio de libros publicados por autor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|Average Books|\n",
      "+-------------+\n",
      "|         2.75|\n",
      "+-------------+\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "columnarBooksDF.groupBy(\"Authors\")\n",
    "  .count()\n",
    "  .agg(round(avg(\"count\"),2).as(\"Average Books\"))\n",
    "  .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8.- Ordenar los libros de mayor a menor (Top 15) por número de ratings dados por usuarios (excluir aquellos valores sin rating)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------+----------------+\n",
      "|Name                                                        |Ratings Received|\n",
      "+------------------------------------------------------------+----------------+\n",
      "|The Catcher in the Rye                                      |985             |\n",
      "|The Great Gatsby                                            |885             |\n",
      "|The Da Vinci Code (Robert Langdon, #2)                      |846             |\n",
      "|To Kill a Mockingbird                                       |830             |\n",
      "|1984                                                        |756             |\n",
      "|The Kite Runner                                             |749             |\n",
      "|Harry Potter and the Sorcerer's Stone (Harry Potter, #1)    |728             |\n",
      "|Animal Farm                                                 |717             |\n",
      "|Harry Potter and the Goblet of Fire (Harry Potter, #4)      |639             |\n",
      "|Harry Potter and the Prisoner of Azkaban (Harry Potter, #3) |631             |\n",
      "|Harry Potter and the Order of the Phoenix (Harry Potter, #5)|595             |\n",
      "|Harry Potter and the Half-Blood Prince (Harry Potter, #6)   |593             |\n",
      "|Pride and Prejudice                                         |580             |\n",
      "|Memoirs of a Geisha                                         |574             |\n",
      "|The Alchemist                                               |556             |\n",
      "|One Hundred Years of Solitude                               |553             |\n",
      "|Me Talk Pretty One Day                                      |535             |\n",
      "|Middlesex                                                   |529             |\n",
      "|Slaughterhouse-Five                                         |504             |\n",
      "|Harry Potter and the Chamber of Secrets (Harry Potter, #2)  |503             |\n",
      "+------------------------------------------------------------+----------------+\n",
      "only showing top 20 rows\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "userRDF.groupBy(\"Name\")\n",
    "  .count()\n",
    "  .where($\"Name\" =!= \"Rating\")\n",
    "  .select($\"Name\",$\"count\".as(\"Ratings Received\"))\n",
    "  .orderBy(desc(\"count\"))\n",
    "  .show(false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**9.- Obtener Top 5 de ratings más frecuentes otorgados por usuarios**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+------+\n",
      "|         Rating| count|\n",
      "+---------------+------+\n",
      "|really liked it|132808|\n",
      "|       liked it| 96047|\n",
      "| it was amazing| 92354|\n",
      "|      it was ok| 28811|\n",
      "|did not like it|  7811|\n",
      "+---------------+------+\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "userRDF.groupBy(\"Rating\")\n",
    "  .count()\n",
    "  .orderBy(desc(\"count\"))\n",
    "  .limit(5)\n",
    "  .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
